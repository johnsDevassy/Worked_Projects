{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_note_1(Extraction).ipynb","provenance":[],"mount_file_id":"144KBXj5Qqu5RRE8-WWA79jeeTNLEFrMK","authorship_tag":"ABX9TyP/TFIM4Or5DrdHxlXva1fO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-ksPh_Ddfa9a","colab_type":"code","colab":{}},"source":["import string\n","import numpy as np\n","from PIL import Image\n","import os\n","from pickle import dump, load\n","import numpy as np\n","from keras.applications.xception import Xception, preprocess_input\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.layers.merge import add\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n","# small library for seeing the progress of loops.\n","from tqdm import tqdm_notebook as tqdm\n","tqdm().pandas()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeP_1MD7IiaM","colab_type":"code","colab":{}},"source":["# Loading a text file into memory\n","def load_doc(filename):\n","    # Opening the file as read only\n","    file = open(filename, 'r')\n","    text = file.read()\n","    file.close()\n","    return text\n","# get all imgs with their captions\n","def all_img_captions(filename):\n","    file = load_doc(filename)\n","    captions = file.split('\\n')\n","    descriptions ={}\n","    for caption in captions[:-1]:\n","        img, caption = caption.split('\\t')\n","        if img[:-2] not in descriptions:\n","            descriptions[img[:-2]] = [ caption ]\n","        else:\n","            descriptions[img[:-2]].append(caption)\n","    return descriptions\n","#Data cleaning- lower casing, removing puntuations and words containing numbers\n","def cleaning_text(captions):\n","    table = str.maketrans('','',string.punctuation)\n","    for img,caps in captions.items():\n","        for i,img_caption in enumerate(caps):\n","            img_caption.replace(\"-\",\" \")\n","            desc = img_caption.split()\n","            #converts to lowercase\n","            desc = [word.lower() for word in desc]\n","            #remove punctuation from each token\n","            desc = [word.translate(table) for word in desc]\n","            #remove hanging 's and a \n","            desc = [word for word in desc if(len(word)>1)]\n","            #remove tokens with numbers in them\n","            desc = [word for word in desc if(word.isalpha())]\n","            #convert back to string\n","            img_caption = ' '.join(desc)\n","            captions[img][i]= img_caption\n","    return captions\n","def text_vocabulary(descriptions):\n","    # build vocabulary of all unique words\n","    vocab = set()\n","    for key in descriptions.keys():\n","        [vocab.update(d.split()) for d in descriptions[key]]\n","    return vocab\n","#All descriptions in one file \n","def save_descriptions(descriptions, filename):\n","    lines = list()\n","    for key, desc_list in descriptions.items():\n","        for desc in desc_list:\n","            lines.append(key + '\\t' + desc )\n","    data = \"\\n\".join(lines)\n","    file = open(filename,\"w\")\n","    file.write(data)\n","    file.close()\n","# Set these path according to project folder in you system\n","dataset_text = \"/content/drive/My Drive/dataset/Flickr8k_Dataset\"\n","dataset_images = \"/content/drive/My Drive/dataset/Flickr8k_Dataset/Flicker8k_Dataset\"\n","#we prepare our text data\n","filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n","#loading the file that contains all data\n","#mapping them into descriptions dictionary img to 5 captions\n","descriptions = all_img_captions(filename)\n","print(\"Length of descriptions =\" ,len(descriptions))\n","#cleaning the descriptions\n","clean_descriptions = cleaning_text(descriptions)\n","#building vocabulary \n","vocabulary = text_vocabulary(clean_descriptions)\n","print(\"Length of vocabulary = \", len(vocabulary))\n","#saving each description to file \n","save_descriptions(clean_descriptions, \"descriptions.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsB1w7x6KQ17","colab_type":"code","colab":{}},"source":["def extract_features(directory):\n","        model = Xception( include_top=False, pooling='avg' )\n","        features = {}\n","        for img in tqdm(os.listdir(directory)):\n","            filename = directory + \"/\" + img\n","            image = Image.open(filename)\n","            image = image.resize((299,299))\n","            image = np.expand_dims(image, axis=0)\n","            #image = preprocess_input(image)\n","            image = image/127.5\n","            image = image - 1.0\n","            feature = model.predict(image)\n","            features[img] = feature\n","        return features\n","#2048 feature vector\n","features = extract_features(dataset_images)\n","dump(features, open(\"features.p\",\"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snr2WJ9FK0Gg","colab_type":"code","colab":{}},"source":["dump(features, open(\"featuresa.txt\",\"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hDjdbJEJStP","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}